# Minimal Docker Compose Example (Frontend + Backend)
 This project demonstrates a minimal docker-compose setup with two services,both running Python:
 - frontend: A simple Streamlit server for the web UI.
 - backend: A Python FastAPI server that receives data and saves it to disk.

## Project Structure
 ```
├── docker-compose.yml
├── README.md
├── backend/
│   ├── Dockerfile
│   ├── main.py
│   └── requirements.txt
└── frontend/
    ├── Dockerfile
    ├── app.py
    └── requirements.txt
```

The `docker compose` plugin is installed by the [install-docker.sh](../../install-docker.sh) script on the VM.
Please note that the plugin uses the command `docker compose` (with a space) instead of `docker-compose` (with a hyphen) which might be necessary if you installed docker compose in another way.

## docker-compose.yml
The `docker-compose.yml` file defines two services: `backend` and `frontend`. Each service has its own build context (where the Dockerfile is located), port mappings, volume mounts for logs and data persistence, and environment variables.

The advantage of mapping volumes is that, in this example, the `./query_data` directory on the host machine will map the `/data` directory inside the backend container, allowing data to be easy accesible and to persist even if the container is removed.

Also note how both services map their log directories to `./logs/<service_name>` on the host machine, making it easy to access logs.

# Backend
The backend has a dockerfile that, at this point, should look familiar.

The `main.py` script is very basic; it has a `/save_query` endpoint that accepts POST requests with a JSON payload containing a `query` string.

The backend saves the query to a timestamped json file in the `/data` directory (which is mapped to `./query_data` on the host). You can imagine that one normally would want to set up a database to store data, but this example is meant to be as basic as possible.

## logging
Note how i payed a bit more attention to logging. Once you are using docker images, it can be a bit difficult to access logs, especially when your service is running somewhere in the cloud.

Setting up logging with loguru is easy, simple and an effective way to be able to check what is going on.

Note that the setup for loguru specifies `rotation="1 MB"`, this makes sure the logfile will not exceed 1Mb of diskspace and is cleaned up automatically. You could also specify timeranges (eg "1 week") with loguru, see their docs for more details.

# frontend
Again, the frontend Dockerfile should not hold any surprises if you have followed along with the previous examples.

The frontend `app.py` script uses Streamlit to create a simple web interface with a text input and a submit button. Typically, streamlit is not scalable and flexible enough for prodcuction, but since we are not doing a course on frontend development, this will do just fine.

Note how I specify `BACKEND_URL` as `http://backend:8000/save_query`, this is possible because docker compose sets up a private network where services can reach each other by their service name.

So, the dataflow goes like this:
- the frontend runs on port 8501 and is accessible via `http://localhost:8501` on the host machine.
- User enters a query in the Streamlit frontend and clicks submit.
- The frontend sends a POST request to the backend's `/save_query` endpoint on port 8000.
- The backend docker service receives the request, processes the data, and saves it to disk.

Now, please go back to the `docker-compose.yml` file and study how we specified the ports and servicenames in order to make this work.

# Running the Example
You can build the two docker containers and the network with:
```bash
docker compose build
```

To start the services, run:
```bash
docker compose up
```

You can also add the build flag to `up` to build the images before starting the containers:
```bash
docker compose up --build
```

If you want to shut down the services, run:
```bash
docker compose down
```

Now, go ahead, spin up the netwerk, open your browser at `http://localhost:8501`, enter a query and see how it gets saved by the backend!

Some things to try:
- Check the `./logs/frontend/` and `./logs/backend/` directories for log files generated by each service.
- check the `./query_data/` directory for the saved query files; does this work as expected?
- Try to trigger an error, eg by submitting without text
- stop the backend service with `docker compose stop backend` and see how the frontend handles the error when trying to submit a query

