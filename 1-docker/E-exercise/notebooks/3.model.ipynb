{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import TextClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data we processed in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "datadir = Path(\"data/processed\")\n",
    "if not datadir.exists():\n",
    "    logger.info(f\"Creating directory {datadir}\")\n",
    "    datadir.mkdir(parents=True)\n",
    "datafile = datadir / Path(\"posts.parquet\")\n",
    "df = pd.read_parquet(datafile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is designed by a Swiss company, specialized in authorship. You can read their blog on the Qanon authorship research with their algorithm [here](https://www.prnewswire.com/news-releases/qanon-is-two-different-people-shows-machine-learning-analysis-from-orphanalytics-301192981.html).\n",
    "\n",
    "While they didnt publish their code, based on their paper i was able to reproduce their results. I implemented their model in the `model.py` file, and we can import it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = TextClustering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will break up the text in k=100 chunks, run a CountVectorizer on trigrams, and then calculate the manhattan distance between the vectors of the chunks. This gives us a `k x k` distance matrix, on which we will run a dimensionality reduction algorithm (PCA or t-SNE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = 100\n",
    "X = clustering(df[\"text\"], k=k, batch=True, method=\"PCA\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the labels as created in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clustering.get_labels(df)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this, we can visualize the results and obtain similar results as in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=labels)\n",
    "\n",
    "imgdir = Path(\"../img\")\n",
    "if not imgdir.exists():\n",
    "    print(f\"Creating directory {imgdir}\")\n",
    "    imgdir.mkdir(parents=True)\n",
    "\n",
    "imgfile = imgdir / Path(\"clustering.png\")\n",
    "plt.savefig(imgfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mads-deployment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
